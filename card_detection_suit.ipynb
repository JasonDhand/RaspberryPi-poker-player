{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "\n",
    "# Create the CNN model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first convolutional layer\n",
    "model.add(Conv2D(64, (5, 5), activation='relu', input_shape=(224, 224, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((3, 3)))\n",
    "\n",
    "# Add the second convolutional layer\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((3, 3)))\n",
    "\n",
    "# Add the third convolutional layer\n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Flatten the output\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add the first dense layer\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7509 files belonging to 4 classes.\n",
      "Found 260 files belonging to 4 classes.\n",
      "Found 260 files belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "####rank detection datasets defined\n",
    "train_path = \"cards_dataset_by_suit\\\\train\"\n",
    "valid_path = \"cards_dataset_by_suit\\\\valid\"\n",
    "test_path = \"cards_dataset_by_suit\\\\test\"\n",
    "\n",
    "batch_size = 32\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "num_classes = 4  # Number of classes in your dataset\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_path,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    label_mode='categorical'  # Use one-hot encoded labels\n",
    ")\n",
    "\n",
    "# Load validation dataset with integer-encoded labels\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    valid_path,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    label_mode='categorical' \n",
    ")\n",
    "\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_path,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    label_mode='categorical',  # Assuming integer-encoded labels for testing dataset\n",
    "    shuffle=False  # Ensure dataset is not shuffled\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "235/235 [==============================] - 212s 897ms/step - loss: 0.9725 - accuracy: 0.5968 - val_loss: 0.8291 - val_accuracy: 0.6154\n",
      "Epoch 2/10\n",
      "235/235 [==============================] - 295s 1s/step - loss: 0.3854 - accuracy: 0.8518 - val_loss: 0.2887 - val_accuracy: 0.9000\n",
      "Epoch 3/10\n",
      "235/235 [==============================] - 722s 3s/step - loss: 0.2688 - accuracy: 0.9012 - val_loss: 0.2230 - val_accuracy: 0.9231\n",
      "Epoch 4/10\n",
      "235/235 [==============================] - 288s 1s/step - loss: 0.2153 - accuracy: 0.9224 - val_loss: 0.1751 - val_accuracy: 0.9462\n",
      "Epoch 5/10\n",
      "235/235 [==============================] - 304s 1s/step - loss: 0.1531 - accuracy: 0.9430 - val_loss: 0.2298 - val_accuracy: 0.9115\n",
      "Epoch 6/10\n",
      "235/235 [==============================] - 303s 1s/step - loss: 0.1224 - accuracy: 0.9588 - val_loss: 0.4261 - val_accuracy: 0.8077\n",
      "Epoch 7/10\n",
      "235/235 [==============================] - 303s 1s/step - loss: 0.0934 - accuracy: 0.9692 - val_loss: 0.4128 - val_accuracy: 0.8577\n",
      "Epoch 8/10\n",
      "235/235 [==============================] - 295s 1s/step - loss: 0.0800 - accuracy: 0.9740 - val_loss: 0.1203 - val_accuracy: 0.9654\n",
      "Epoch 9/10\n",
      "235/235 [==============================] - 304s 1s/step - loss: 0.0618 - accuracy: 0.9799 - val_loss: 0.0744 - val_accuracy: 0.9654\n",
      "Epoch 10/10\n",
      "235/235 [==============================] - 212s 900ms/step - loss: 0.0715 - accuracy: 0.9768 - val_loss: 0.1829 - val_accuracy: 0.9154\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hist = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "235/235 [==============================] - 221s 937ms/step - loss: 0.0569 - accuracy: 0.9823 - val_loss: 0.1426 - val_accuracy: 0.9654\n",
      "Epoch 2/2\n",
      "235/235 [==============================] - 212s 902ms/step - loss: 0.0476 - accuracy: 0.9855 - val_loss: 0.1703 - val_accuracy: 0.9423\n"
     ]
    }
   ],
   "source": [
    "addhist = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: suit_classification\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: suit_classification\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('suit_classification')\n",
    "model.save_weights('suit_classification.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_model = tf.keras.models.load_model('suit_classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 2s 188ms/step - loss: 0.1593 - accuracy: 0.9423\n",
      "Test accuracy: 0.942307710647583\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = rank_model.evaluate(test_ds)\n",
    "\n",
    "print(f'Test accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path, desired_size=(224, 224)):\n",
    "    # Open the image\n",
    "    image = Image.open(image_path)\n",
    "    \n",
    "    # Resize the image using the ANTIALIAS (high-quality) interpolation method\n",
    "    # resized_image = image.resize(desired_size, Image.ANTIALIAS)\n",
    "    \n",
    "    # Return the resized image\n",
    "    return image\n",
    "    # return resized_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 96ms/step\n",
      "Predicted class: diamonds\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "classes = [\"clubs\", \"diamonds\", \"hearts\", \"spades\"]\n",
    "# File path to the image\n",
    "# image_path = \"C:\\\\Users\\\\jason\\\\ECE_479\\\\final_project_3\\\\cards_dataset_by_suit\\\\test\\\\clubs\\\\1_1.jpg\"\n",
    "image_path = \"cropped_image.jpg\"\n",
    "# Load and preprocess the image using TensorFlow\n",
    "image = tf.keras.preprocessing.image.load_img(image_path, target_size=(img_height, img_width))\n",
    "image_array = tf.keras.preprocessing.image.img_to_array(image)\n",
    "image_array = tf.expand_dims(image_array, axis=0)  # Add batch dimension\n",
    "\n",
    "# Make prediction\n",
    "predictions = model.predict(image_array)\n",
    "predicted_class = np.argmax(predictions, axis=1)\n",
    "print(\"Predicted class:\", classes[int(predicted_class)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
