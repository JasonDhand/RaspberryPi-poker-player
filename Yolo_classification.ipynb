{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import layers, models\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from keras.callbacks import EarlyStopping\n",
    "from ultralytics import YOLO \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.5 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.2.4  Python-3.8.18 torch-2.3.0+cpu CPU (13th Gen Intel Core(TM) i7-13700H)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=C:\\Users\\jason\\ECE_479\\final_project_2\\cards_dataset, epochs=25, time=None, patience=100, batch=16, imgsz=224, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train5, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\train5\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\jason\\ECE_479\\final_project_2\\cards_dataset\\train... found 7624 images in 53 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\jason\\ECE_479\\final_project_2\\cards_dataset\\validation... found 265 images in 53 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\jason\\ECE_479\\final_project_2\\cards_dataset\\test... found 265 images in 53 classes  \n",
      "Overriding model.yaml nc=1000 with nc=53\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    398133  ultralytics.nn.modules.head.Classify         [256, 53]                     \n",
      "YOLOv8n-cls summary: 99 layers, 1506181 parameters, 1506181 gradients, 3.4 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\classify\\train5', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\jason\\ECE_479\\final_project_2\\cards_dataset\\train... 7624 images, 0 corrupt: 100%|██████████| 7624/7624 [00:16<00:00, 454.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\jason\\ECE_479\\final_project_2\\cards_dataset\\train.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\jason\\ECE_479\\final_project_2\\cards_dataset\\validation... 265 images, 0 corrupt: 100%|██████████| 265/265 [00:00<00:00, 337.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\jason\\ECE_479\\final_project_2\\cards_dataset\\validation.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 224 train, 224 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\classify\\train5\u001b[0m\n",
      "Starting training for 25 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/25         0G      3.347          8        224: 100%|██████████| 477/477 [07:29<00:00,  1.06it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 9/9 [00:06<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.343      0.845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/25         0G      2.014          8        224: 100%|██████████| 477/477 [11:46<00:00,  1.48s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 9/9 [00:01<00:00,  5.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.63      0.936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/25         0G      1.521          8        224: 100%|██████████| 477/477 [07:25<00:00,  1.07it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 9/9 [00:01<00:00,  5.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.766      0.962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/25         0G       1.24          8        224: 100%|██████████| 477/477 [02:41<00:00,  2.95it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 9/9 [00:01<00:00,  5.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.804      0.958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/25         0G      1.081          8        224: 100%|██████████| 477/477 [02:43<00:00,  2.92it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 9/9 [00:01<00:00,  5.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.826      0.985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/25         0G     0.9581          8        224: 100%|██████████| 477/477 [03:00<00:00,  2.65it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 9/9 [00:01<00:00,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.845      0.985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/25         0G     0.8614          8        224: 100%|██████████| 477/477 [06:06<00:00,  1.30it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 9/9 [00:04<00:00,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.887      0.989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/25         0G     0.8015          8        224: 100%|██████████| 477/477 [09:05<00:00,  1.14s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 9/9 [00:05<00:00,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.894      0.989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/25         0G     0.7413          8        224: 100%|██████████| 477/477 [12:08<00:00,  1.53s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 9/9 [00:05<00:00,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.891      0.989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/25         0G     0.7014          8        224: 100%|██████████| 477/477 [07:51<00:00,  1.01it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 9/9 [00:04<00:00,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.906      0.992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/25         0G     0.6549          8        224: 100%|██████████| 477/477 [10:05<00:00,  1.27s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 9/9 [00:05<00:00,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.917          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/25         0G     0.6068          8        224: 100%|██████████| 477/477 [12:09<00:00,  1.53s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 9/9 [00:05<00:00,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.94      0.992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/25         0G     0.5782          8        224: 100%|██████████| 477/477 [13:43<00:00,  1.73s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 9/9 [00:04<00:00,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.906      0.996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/25         0G     0.5437          8        224: 100%|██████████| 477/477 [36:08<00:00,  4.55s/it]   \n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 9/9 [00:10<00:00,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.94          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/25         0G     0.5349          8        224: 100%|██████████| 477/477 [06:33<00:00,  1.21it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 9/9 [00:01<00:00,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.928      0.996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/25         0G     0.4993          8        224: 100%|██████████| 477/477 [02:39<00:00,  2.99it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 9/9 [00:01<00:00,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.928          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/25         0G     0.4922          8        224: 100%|██████████| 477/477 [02:37<00:00,  3.02it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 9/9 [00:01<00:00,  5.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.951          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/25         0G     0.4541          8        224: 100%|██████████| 477/477 [02:36<00:00,  3.05it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 9/9 [00:01<00:00,  5.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.94          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/25         0G     0.4423          8        224: 100%|██████████| 477/477 [02:40<00:00,  2.97it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 9/9 [00:01<00:00,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.955          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/25         0G     0.4333          8        224: 100%|██████████| 477/477 [02:40<00:00,  2.97it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 9/9 [00:01<00:00,  5.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.94          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/25         0G     0.4055          8        224: 100%|██████████| 477/477 [03:18<00:00,  2.40it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 9/9 [00:01<00:00,  4.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.932          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/25         0G     0.3928          8        224: 100%|██████████| 477/477 [06:15<00:00,  1.27it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 9/9 [00:01<00:00,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.94          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/25         0G     0.3791          8        224: 100%|██████████| 477/477 [02:40<00:00,  2.98it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 9/9 [00:01<00:00,  4.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.943          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/25         0G     0.3776          8        224: 100%|██████████| 477/477 [02:37<00:00,  3.02it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 9/9 [00:01<00:00,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.94          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/25         0G     0.3711          8        224: 100%|██████████| 477/477 [02:39<00:00,  2.99it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 9/9 [00:01<00:00,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.932          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "25 epochs completed in 3.023 hours.\n",
      "Optimizer stripped from runs\\classify\\train5\\weights\\last.pt, 3.1MB\n",
      "Optimizer stripped from runs\\classify\\train5\\weights\\best.pt, 3.1MB\n",
      "\n",
      "Validating runs\\classify\\train5\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.4  Python-3.8.18 torch-2.3.0+cpu CPU (13th Gen Intel Core(TM) i7-13700H)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 1502773 parameters, 0 gradients, 3.3 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\jason\\ECE_479\\final_project_2\\cards_dataset\\train... found 7624 images in 53 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\jason\\ECE_479\\final_project_2\\cards_dataset\\validation... found 265 images in 53 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\jason\\ECE_479\\final_project_2\\cards_dataset\\test... found 265 images in 53 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 9/9 [00:01<00:00,  4.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.955          1\n",
      "Speed: 0.0ms preprocess, 4.0ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\train5\u001b[0m\n",
      "Results saved to \u001b[1mruns\\classify\\train5\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# batch_size = 32\n",
    "# img_height = 224\n",
    "# img_width = 224\n",
    "# num_classes = 13  # Number of classes in your dataset\n",
    "\n",
    "\n",
    "\n",
    "# Path to your dataset\n",
    "# training_dataset_path = \"C:\\\\Users\\\\jason\\\\ECE 479\\\\final_project_2\\\\card_dataset\\\\train\"\n",
    "# validation_dataset_path = \n",
    "# \"C:\\\\Users\\\\jason\\\\ECE 479\\\\final_project_2\\\\card_dataset\\\\valid\"\n",
    "path = \"C:\\\\Users\\\\jason\\\\ECE_479\\\\final_project_2\\\\cards_dataset\"\n",
    "\n",
    "\n",
    "\n",
    "# # Load training dataset with integer-encoded labels\n",
    "# train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "#     training_dataset_path,\n",
    "#     image_size=(img_height, img_width),\n",
    "#     batch_size=batch_size,\n",
    "#     label_mode='int'  # Use integer-encoded labels\n",
    "# )\n",
    "\n",
    "# # Load validation dataset with integer-encoded labels\n",
    "# val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "#     validation_dataset_path,\n",
    "#     image_size=(img_height, img_width),\n",
    "#     batch_size=batch_size,\n",
    "#     label_mode='int'  # Use integer-encoded labels\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "# input_shape = (224, 224, 3)\n",
    "\n",
    "# # Create a Sequential model\n",
    "# model = tf.keras.Sequential([\n",
    "#     tf.keras.layers.Conv2D(input_shape=input_shape, filters=64, kernel_size=(11, 11), strides=(4, 4), padding='valid', activation='relu'),\n",
    "#     tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='valid'),\n",
    "#     tf.keras.layers.Conv2D(filters=192, kernel_size=(5, 5), strides=(1, 1), padding='same', activation='relu'),\n",
    "#     tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='valid'),\n",
    "#     tf.keras.layers.Conv2D(filters=384, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu'),\n",
    "#     tf.keras.layers.Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu'),\n",
    "#     tf.keras.layers.Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu'),\n",
    "#     tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='valid'),\n",
    "#     tf.keras.layers.Flatten(),\n",
    "#     tf.keras.layers.Dense(4096, activation='relu'),\n",
    "#     tf.keras.layers.Dropout(0.5),\n",
    "#     tf.keras.layers.Dense(4096, activation='relu'),\n",
    "#     tf.keras.layers.Dropout(0.5),\n",
    "#     tf.keras.layers.Dense(13, activation='softmax')\n",
    "# ])\n",
    "\n",
    "# # Compile the model\n",
    "# model.compile(optimizer='adam',\n",
    "#                loss='sparse_categorical_crossentropy',  # Use sparse categorical crossentropy loss\n",
    "#                metrics=['accuracy'])\n",
    "\n",
    "# model = YOLO('yolov8s-cls.yaml')  # build a new model from YAML\n",
    "# # load a pretrained model (recommended for training)\n",
    "model = YOLO('yolov8n-cls.pt')\n",
    "# # build from YAML and transfer weights\n",
    "# model = YOLO('yolov8n-cls.yaml').load('yolov8n-cls.pt')\n",
    "\n",
    "# Train the model\n",
    "results = model.train(data=path, epochs=25, imgsz=224)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('./runs/classify/train5/weights/best.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.4  Python-3.8.18 torch-2.3.0+cpu CPU (13th Gen Intel Core(TM) i7-13700H)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 1502773 parameters, 0 gradients, 3.3 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\jason\\ECE_479\\final_project_2\\cards_dataset\\train... found 7624 images in 53 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\jason\\ECE_479\\final_project_2\\cards_dataset\\validation... found 265 images in 53 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\jason\\ECE_479\\final_project_2\\cards_dataset\\test... found 265 images in 53 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\jason\\ECE_479\\final_project_2\\cards_dataset\\validation... 265 images, 0 corrupt: 100%|██████████| 265/265 [00:00<?, ?it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 17/17 [00:02<00:00,  7.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.955          1\n",
      "Speed: 0.0ms preprocess, 4.6ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\val\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9547169804573059"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = model.val()  # no arguments needed, dataset and settings remembered\n",
    "metrics.top1   # top1 accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path, desired_size=(224, 224)):\n",
    "    # Open the image\n",
    "    image = Image.open(image_path)\n",
    "    \n",
    "    # Resize the image using the ANTIALIAS (high-quality) interpolation method\n",
    "    # resized_image = image.resize(desired_size, Image.ANTIALIAS)\n",
    "    \n",
    "    # Return the resized image\n",
    "    return image\n",
    "    # return resized_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cropped_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 11\u001b[0m\n\u001b[0;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./runs/classify/train5/weights/best.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Path to the image you want to test\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# image_path = 'C:\\\\Users\\\\jason\\\\ECE_479\\\\final_project_2\\\\PiCam images\\\\2S.png'\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# image_path = 'C:\\\\Users\\\\jason\\\\ECE_479\\\\final_project_2\\\\screenshots\\\\9_diamonds.png'\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m image_path \u001b[38;5;241m=\u001b[39m \u001b[43mcropped_image\u001b[49m\u001b[38;5;241m.\u001b[39mjpg\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Preprocess the image\u001b[39;00m\n\u001b[0;32m     13\u001b[0m image_tensor \u001b[38;5;241m=\u001b[39m preprocess_image(image_path)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cropped_image' is not defined"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the YOLO model\n",
    "model = YOLO('./runs/classify/train5/weights/best.pt')\n",
    "\n",
    "\n",
    "# Path to the image you want to test\n",
    "# image_path = 'C:\\\\Users\\\\jason\\\\ECE_479\\\\final_project_2\\\\PiCam images\\\\2S.png'\n",
    "# image_path = 'C:\\\\Users\\\\jason\\\\ECE_479\\\\final_project_2\\\\screenshots\\\\9_diamonds.png'\n",
    "image_path = \"cropped_image.jpg\"\n",
    "# Preprocess the image\n",
    "image_tensor = preprocess_image(image_path)\n",
    "\n",
    "# Perform inference on the preprocessed image\n",
    "results = model(image_tensor)\n",
    "\n",
    "# Visualize each result separately\n",
    "for result in results:\n",
    "    result.show()  # Show the annotated image with bounding boxes\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5/5 [==============================] - 5s 764ms/step - loss: 55.2672 - accuracy: 0.1026 - val_loss: 2.6332 - val_accuracy: 0.0962\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 3s 686ms/step - loss: 2.5930 - accuracy: 0.0577 - val_loss: 2.6094 - val_accuracy: 0.0769\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 3s 678ms/step - loss: 2.5786 - accuracy: 0.0705 - val_loss: 2.5703 - val_accuracy: 0.0769\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 3s 690ms/step - loss: 2.5646 - accuracy: 0.0833 - val_loss: 2.5634 - val_accuracy: 0.0769\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 3s 675ms/step - loss: 2.5634 - accuracy: 0.0833 - val_loss: 2.5611 - val_accuracy: 0.0769\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 3s 679ms/step - loss: 2.5612 - accuracy: 0.0513 - val_loss: 2.5598 - val_accuracy: 0.0962\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 3s 676ms/step - loss: 2.5493 - accuracy: 0.0577 - val_loss: 2.5576 - val_accuracy: 0.0769\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 3s 679ms/step - loss: 2.5412 - accuracy: 0.0705 - val_loss: 2.5525 - val_accuracy: 0.0769\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 3s 694ms/step - loss: 2.5309 - accuracy: 0.1026 - val_loss: 2.5453 - val_accuracy: 0.0577\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 3s 674ms/step - loss: 2.5085 - accuracy: 0.1410 - val_loss: 2.5632 - val_accuracy: 0.0769\n"
     ]
    }
   ],
   "source": [
    "# hist = model.fit(\n",
    "#     train_ds,\n",
    "#     validation_data=val_ds,\n",
    "#     epochs=num_epochs,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
