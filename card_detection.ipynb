

import tensorflow as tf
from keras import layers, models
import numpy as np
from tensorflow.keras.preprocessing import image
import matplotlib.pyplot as plt

# Path to your dataset

training_dataset_path = "cards_dataset\\train"
validation_dataset_path = "cards_dataset\\valid"

# gpus = tf.config.list_physical_devices('GPU')
# if gpus:
#     # GPU(s) available, print information about each GPU
#     for gpu in gpus:
#         print("Name:", gpu.name)
#         print("Device type:", gpu.device_type)
# else:
#     print("No GPU(s) detected.")
batch_size = 32
img_height = 224
img_width = 224
num_classes = 53  # Number of classes in your dataset

# Load training dataset with integer-encoded labels
train_ds = tf.keras.preprocessing.image_dataset_from_directory(
    training_dataset_path,
    image_size=(img_height, img_width),
    batch_size=batch_size,
    label_mode='int'  # Use integer-encoded labels
)

# Load validation dataset with integer-encoded labels
val_ds = tf.keras.preprocessing.image_dataset_from_directory(
    validation_dataset_path,
    image_size=(img_height, img_width),
    batch_size=batch_size,
    label_mode='int'  # Use integer-encoded labels
)

model = tf.keras.Sequential([
    tf.keras.layers.Conv2D(input_shape=(224, 224, 3), kernel_size=(5, 5), strides=(1, 1), padding='same', activation='relu', filters=4),
    tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),
    tf.keras.layers.Conv2D(filters=8, kernel_size=(3, 3), strides=(1, 1), padding='valid', activation='relu'),
    tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128),
    tf.keras.layers.BatchNormalization(),  # Add batch normalization layer
    tf.keras.layers.Activation('relu'),    # Add activation after batch normalization
    tf.keras.layers.Dropout(0.5),          # Add dropout layer with dropout rate of 0.5
    tf.keras.layers.Dense(64),
    tf.keras.layers.BatchNormalization(),  # Add batch normalization layer
    tf.keras.layers.Activation('relu'),    # Add activation after batch normalization
    tf.keras.layers.Dropout(0.5),          # Add dropout layer with dropout rate of 0.5
    tf.keras.layers.Dense(53, activation='softmax')  # 53 output neurons for the 53 different playing cards
])




num_epochs = 10


model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',  # Use sparse categorical crossentropy loss
              metrics=['accuracy'])





# Train the model
history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=num_epochs
)
additional_epochs = 10

additional_history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=additional_epochs
)

model.save_weights('your_model_weights.h5')
# Save the model
model.save('my_model')

# Load the saved model
loaded_model = tf.keras.models.load_model('my_model')


# # Load testing dataset
# testing_dataset_path = "cards_dataset\\test"
# test_ds = tf.keras.preprocessing.image_dataset_from_directory(
#     testing_dataset_path,
#     image_size=(img_height, img_width),
#     batch_size=batch_size,
#     label_mode='int'  # Assuming integer-encoded labels for testing dataset
# )

# # Evaluate the model on the testing dataset
# test_loss, test_accuracy = model.evaluate(test_ds)

# print(f'Test accuracy: {test_accuracy}')


# Load testing dataset
testing_dataset_path = "cards_dataset\\test"
test_ds = tf.keras.preprocessing.image_dataset_from_directory(
    testing_dataset_path,
    image_size=(img_height, img_width),
    batch_size=batch_size,
    label_mode='int',  # Assuming integer-encoded labels for testing dataset
    shuffle=False  # Ensure dataset is not shuffled
)

# Evaluate the model on the testing dataset
test_loss, test_accuracy = loaded_model.evaluate(test_ds)

print(f'Test accuracy: {test_accuracy}')

# Iterate through the testing dataset and make predictions
# for images, labels in test_ds:
#     predictions = model.predict(images)
#     predicted_classes = np.argmax(predictions, axis=1)
    
    # # Display images and their predictions
    # for i in range(len(images)):
    #     image_array = images[i].numpy().astype(np.uint8)
    #     plt.imshow(image_array)
    #     plt.title(f"True Label: {labels[i]}, Predicted Label: {predicted_classes[i]}")
    #     plt.show()
    #     #print(f"True Label: {labels[i]}, Predicted Label: {predicted_classes[i]}")
 
 
###########other tests to show accuracy-used pictures from the web (see cards.csv for accurate labels)


from PIL import Image
import tensorflow as tf

# File path to the image
image_path = "cards_dataset\\other_tests\\Img2.png"

# Load and preprocess the image using TensorFlow
image = tf.keras.preprocessing.image.load_img(image_path, target_size=(img_height, img_width))
image_array = tf.keras.preprocessing.image.img_to_array(image)
image_array = tf.expand_dims(image_array, axis=0)  # Add batch dimension

# Make prediction
predictions = model.predict(image_array)
predicted_class = np.argmax(predictions, axis=1)
print("Predicted class:", predicted_class)

# plt.imshow(image)
        

converter = tf.lite.TFLiteConverter.from_keras_model(loaded_model)
tflite_model = converter.convert()

with open("my_model.tflite", "wb") as f:
    f.write(tflite_model)
